---
title: "Machine Learning Project: Prediction"
author: "Natali Pérez"
date: "`r Sys.Date()`"
output: html_document
---

## 1. Introduction
This report documents the process of developing a predictive model to classify the manner in which subjects perform weight lifting exercises. Using accelerometer and gyroscope data from wearable devices, we trained a Random Forest classifier on a labeled dataset and generated predictions for a 20-case test set. The main objectives were to ensure data quality, select relevant features, validate model performance, and produce accurate predictions for submission.


# 1. Load Required Packages

```{r setup_librerias, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(randomForest)
```


```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "C:/Users/Compumax/Desktop/ProyectoML")
```

# Set working directory
```{r set_working_directory, include=TRUE}
setwd("C:/Users/Compumax/Desktop/ProyectoML")
```

## 2. Exploratory Data Analysis
```{r Exploratory, include=TRUE}
training <- read.csv("C:/Users/Compumax/Desktop/pml-training.csv", stringsAsFactors = FALSE)
testing  <- read.csv("C:/Users/Compumax/Desktop/pml-testing.csv", stringsAsFactors = FALSE)
```

#  3. Clean the training set
```{r clean, include=TRUE}
training <- training %>%
  select_if(~ mean(is.na(.)) < 0.95) %>%
  select(-c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,
            cvtd_timestamp, new_window, num_window))
```

# 4. Split into training and internal validation sets
```{r training_sets, include=TRUE}
set.seed(123)
inTrain <- createDataPartition(training$classe, p = 0.7, list = FALSE)
trainSet <- training[inTrain, ]
testSet  <- training[-inTrain, ]
trainSet$classe <- as.factor(trainSet$classe)
testSet$classe  <- factor(testSet$classe, levels = levels(trainSet$classe))
```

# 5. Train the model using only common variables without NAs
```{r train_model, include=TRUE}
# Train the Random Forest Model with Shared Clean Variables
common_vars <- intersect(names(trainSet), names(testing))
common_vars <- setdiff(common_vars, "classe")
train_reduced <- trainSet[, c(common_vars, "classe")]

# Convert to numeric without printing warnings about coercion
train_reduced[, common_vars] <- suppressWarnings(
  lapply(train_reduced[, common_vars], function(x) as.numeric(as.character(x)))
)

# Remove columns with missing values
non_na_cols <- colSums(is.na(train_reduced)) == 0
train_reduced <- train_reduced[, non_na_cols]

# Train final model
final_model <- randomForest(classe ~ ., data = train_reduced, ntree = 100)

# Plot variable importance (optional but insightful)
varImpPlot(final_model)
```

# 6 Evaluate the model with validation subset
```{r Evaluate_model, include=TRUE}
# Use only the variables included in the final model
final_vars <- setdiff(names(train_reduced), "classe")
test_reduced <- testSet[, final_vars]

# Convert to numeric format without displaying warnings
test_reduced <- data.frame(
  suppressWarnings(
    lapply(test_reduced, function(x) as.numeric(as.character(x)))
  )
)

# Make predictions and evaluate the model
pred_eval <- predict(final_model, newdata = test_reduced)
confusionMatrix(pred_eval, testSet$classe)
```

# 7. Prepare the testing set with variables used by the model
```{r testing, include=TRUE}
testing_final <- testing[, final_vars]
testing_final <- data.frame(lapply(testing_final, function(x) as.numeric(as.character(x))))
```

# 8.  Predict the 20 cases from the testing set
```{r predict, include=TRUE}
final_predictions <- predict(final_model, newdata = testing_final)
final_predictions
```
#Explanation: These are the 20 predictions required for submission. Ensure you copy these in the format your course’s prediction quiz expects.


# Conclusion
The final Random Forest model achieved an internal validation accuracy of 99.49%, with balanced accuracy across all classes near or above 99.5%. The modeling process included careful data cleaning, validation, and compatibility alignment with the final test set. The model was successfully used to predict the outcomes for the 20 cases provided, completing the practical machine learning assignment.
